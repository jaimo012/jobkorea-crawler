# íŒŒì¼ ì´ë¦„: main.py (ì´ ë‚´ìš©ìœ¼ë¡œ ë®ì–´ì“°ê¸°)

# ==============================================================================
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (ì´ì „ê³¼ ë™ì¼)
# ==============================================================================
import time
import datetime
import random
import re
import pandas as pd
import pyperclip
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.common.action_chains import ActionChains
from libs import OpenGooglesheets as Google

# ==============================================================================
# 2. ìƒìˆ˜(CONSTANTS) ì •ì˜ (ì´ì „ê³¼ ë™ì¼)
# ==============================================================================
JOBKOREA_LOGIN_URL = 'https://www.jobkorea.co.kr/Login'
JOBKOREA_SEARCH_URL = 'https://www.jobkorea.co.kr/recruit/joblist?menucode=local&localorder=1'
JOBKOREA_ID = 'misojaimo'
JOBKOREA_PW = 'qawsedrftg!@#'

JD_LIST_SPREADSHEET_URL = 'https://docs.google.com/spreadsheets/d/1Fif7KZEL9MEj3IslfGgVV30SsAQd4tNwMIOynQ7q2Ow/edit#gid=0'
JD_LIST_SHEET_NAME = 'ì „ì²´JD'
CONTACT_SPREADSHEET_URL = 'https://docs.google.com/spreadsheets/d/1Fif7KZEL9MEj3IslfGgVV30SsAQd4tNwMIOynQ7q2Ow/edit#gid=1614047783'
CONTACT_SHEET_NAME = 'ì—°ë½ì²˜'
EXCLUSION_SPREADSHEET_URL = 'https://docs.google.com/spreadsheets/d/1Fif7KZEL9MEj3IslfGgVV30SsAQd4tNwMIOynQ7q2Ow/edit#gid=1781334674'
EXCLUSION_SHEET_NAME = 'ì œì™¸ë¦¬ìŠ¤íŠ¸'
EXCLUSION_JD_TITLE_PATTERN = r"(?i)abap|sap|ê°•ì‚¬|ìˆ˜ë¦¬|ì½”ì¹˜|ë©˜í† "

# ==============================================================================
# 3. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ (ì´ì „ê³¼ ë™ì¼)
# ==============================================================================
# initialize_driver, login_to_jobkorea, ... scrape_company_details ë“± ëª¨ë“  í•¨ìˆ˜ëŠ”
# ì´ì „ ë‹µë³€ê³¼ ë™ì¼í•˜ê²Œ ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ë³µì‚¬/ë¶™ì—¬ë„£ê¸° í•©ë‹ˆë‹¤.
def initialize_driver():
    """ì…€ë ˆë‹ˆì›€ ì›¹ë“œë¼ì´ë²„ë¥¼ ì´ˆê¸°í™”í•˜ê³  ë°˜í™˜í•©ë‹ˆë‹¤."""
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_experimental_option("excludeSwitches", ["ignore-certificate-errors", "ignore-ssl-errors"])
    driver = webdriver.Chrome(options=options)
    driver.implicitly_wait(10)
    print("âœ… ì›¹ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì™„ë£Œ")
    return driver

def login_to_jobkorea(driver, user_id, user_pw):
    """ì£¼ì–´ì§„ ë“œë¼ì´ë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¡ì½”ë¦¬ì•„ì— ë¡œê·¸ì¸í•©ë‹ˆë‹¤."""
    print("â³ ì¡ì½”ë¦¬ì•„ ë¡œê·¸ì¸ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    driver.get(JOBKOREA_LOGIN_URL)
    time.sleep(random.uniform(0.5, 1.0))
    id_input = driver.find_element(By.NAME, 'M_ID')
    id_input.click()
    pyperclip.copy(user_id)
    id_input.send_keys(Keys.CONTROL, 'v')
    time.sleep(random.uniform(0.5, 1.0))
    pw_input = driver.find_element(By.NAME, 'M_PWD')
    pw_input.click()
    pyperclip.copy(user_pw)
    pw_input.send_keys(Keys.CONTROL, 'v')
    time.sleep(random.uniform(0.5, 1.0))
    driver.find_element(By.CLASS_NAME, 'login-button').click()
    time.sleep(random.uniform(2, 4))
    print("âœ… ë¡œê·¸ì¸ ì„±ê³µ!")

def safe_extract_text(element, selector, default=""):
    try:
        target = element.select_one(selector)
        return target.text.strip() if target else default
    except Exception:
        return default

def safe_extract_attr(element, selector, attr, default=""):
    try:
        target = element.select_one(selector)
        return target[attr].strip() if target and attr in target.attrs else default
    except Exception:
        return default

def parse_jd_list_page(page_source):
    soup = BeautifulSoup(page_source, 'html.parser')
    jd_list_container = soup.find('div', id="dev-gi-list")
    if not jd_list_container: return []
    jd_rows = jd_list_container.find_all('tr', class_="devloopArea")
    page_data = []
    for jd_row in jd_rows:
        jd_title_element = jd_row.select_one('td.tplTit a.link.normalLog')
        data = {
            'ê¸°ì—…ëª…': safe_extract_text(jd_row, 'td.tplCo a.link.normalLog'),
            'ê¸°ì—…ë§í¬': 'https://www.jobkorea.co.kr' + safe_extract_attr(jd_row, 'td.tplCo a.link.normalLog', 'href'),
            'JDëª…': jd_title_element.text.strip() if jd_title_element else "",
            'ë“±ë¡ì¼': safe_extract_text(jd_row, 'td.odd span.time'),
            'ë§ˆê°ê¸°í•œ': safe_extract_text(jd_row, 'td.odd span.date'),
            'JDë§í¬': 'https://www.jobkorea.co.kr' + jd_title_element['href'].strip() if jd_title_element else "",
            'ì‘ì—…ëŒ€ìƒ': "Wait",
            'ìˆ˜ì§‘ì¼ì‹œ': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        page_data.append(data)
    return page_data

def scrape_company_details(driver, company_url):
    driver.get(company_url)
    time.sleep(random.uniform(1, 2))
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    company_info = {
        'ê¸°ì—…ëª…(ê²€ìƒ‰ê²°ê³¼)': safe_extract_text(soup, 'div.company-header-branding-body div.name'),
        'ê¸°ì—…êµ¬ë¶„': "", 'ëŒ€í‘œì': "", 'í™ˆí˜ì´ì§€': "", 'ì„¤ë¦½ì¼': "", 'ì‚°ì—…': "", 'ì£¼ìš”ì‚¬ì—…': "",
        'ì‚¬ì›ìˆ˜': "", 'ë§¤ì¶œì•¡': "", 'ìë³¸ê¸ˆ': "", 'ì£¼ì†Œ': ""
    }
    info_container = soup.find('div', class_="company-infomation-container basic-infomation-container")
    if not info_container: return company_info
    info_rows = info_container.find_all('tr')
    for row in info_rows:
        labels = row.find_all('th', class_="field-label")
        values = row.find_all('div', class_="value")
        for i in range(min(len(labels), len(values))):
            label = labels[i].text.replace('\n', '').replace(' ', '').strip()
            value = values[i].text.strip()
            if label in company_info:
                company_info[label] = value
    return company_info

def get_contact_details(driver, jd_link):
    driver.get(jd_link)
    try:
        more_info_button_xpath = "//span[contains(text(), 'ë‹´ë‹¹ì ì •ë³´ ë” ë³´ê¸°')]/ancestor::button"
        wait = WebDriverWait(driver, 5)
        more_info_button = wait.until(EC.element_to_be_clickable((By.XPATH, more_info_button_xpath)))
        more_info_button.click()
        print("   - 'ë‹´ë‹¹ì ì •ë³´ ë” ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ì„±ê³µ!")
        time.sleep(random.uniform(0.5, 1.0))
    except TimeoutException:
        print("   - 'ë‹´ë‹¹ì ì •ë³´ ë” ë³´ê¸°' ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (Timeout)")
    except Exception as e:
        print(f"   - ë²„íŠ¼ í´ë¦­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    soup = BeautifulSoup(driver.page_source, 'html.parser')
    application_section = soup.find('div', id="application-section")
    if not application_section: return None
    def _parse_manager_info(section):
        manager_name = "ì •ë³´ ì—†ìŒ"; department_name = "ì •ë³´ ì—†ìŒ"
        manager_div = section.find('div', attrs={'data-sentry-component': 'HrManagerContact'})
        if manager_div and (name_span := manager_div.find('span')):
            full_text = name_span.get_text(strip=True)
            if '(' in full_text and ')' in full_text:
                parts = full_text.split('(')
                manager_name = parts[0].strip(); department_name = parts[1].replace(')', '').strip()
            else: manager_name = full_text
        return manager_name, department_name
    def _get_contact_value(section, label_text):
        if not (label_element := section.find('span', string=re.compile(r'\s*' + label_text + r'\s*'))): return "ì •ë³´ ì—†ìŒ"
        if not (value_container := label_element.parent.find_next_sibling('div')): return "ì •ë³´ ì—†ìŒ"
        return (value_element.get_text(strip=True) if (value_element := value_container.find('span')) else "ì •ë³´ ì—†ìŒ")
    manager_name, department_name = _parse_manager_info(application_section)
    return {
        'ì´ë¦„': manager_name, 'ì†Œì†': department_name, 'ì „í™”ë²ˆí˜¸': _get_contact_value(application_section, "ì „í™”ë²ˆí˜¸"),
        'íœ´ëŒ€ì „í™”': _get_contact_value(application_section, "íœ´ëŒ€í°"), 'ì´ë©”ì¼': _get_contact_value(application_section, "ì´ë©”ì¼")
    }

def get_jd_details(driver, jd_link):
    return {}

def run_phase1(driver):
    # Phase 1 ë¡œì§ ... (ì´ì „ê³¼ ë™ì¼)
    print("ğŸš€ [Phase 1] ì±„ìš© ê³µê³  ëª©ë¡ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("â³ êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ ê¸°ì¡´ JD ëª©ë¡ê³¼ ì œì™¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
    JD_LIST_sheet, JD_LIST_df = Google.OpenGooglesheets(JD_LIST_SPREADSHEET_URL, JD_LIST_SHEET_NAME)
    _, EXCLUSION_df = Google.OpenGooglesheets(EXCLUSION_SPREADSHEET_URL, EXCLUSION_SHEET_NAME)
    print(f"âœ… ê¸°ì¡´ JD {len(JD_LIST_df)}ê±´, ì œì™¸ ê¸°ì—… {len(EXCLUSION_df)}ê±´ ë¡œë“œ ì™„ë£Œ.")

    print("â³ JD ëª©ë¡ ìŠ¤í¬ë˜í•‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    driver.get(JOBKOREA_SEARCH_URL)
    time.sleep(random.uniform(2, 4))
    driver.find_element(By.ID, 'devSearchedTerms').click()
    time.sleep(random.uniform(0.5, 1.0))
    driver.find_element(By.CSS_SELECTOR, "#devSearchedTermsLayer > div > div.tplList > table > tbody > tr > td.tit.dev-condition-select > span").click()
    time.sleep(random.uniform(2, 4))
    all_jds = []
    current_page = 1
    MAX_PAGE = 999 
    while current_page <= MAX_PAGE:
        print(f"   - {current_page} í˜ì´ì§€ ìˆ˜ì§‘ ì¤‘...")
        try:
            jd_elements = driver.find_elements(By.CSS_SELECTOR, "#dev-gi-list .devloopArea")
            if jd_elements: ActionChains(driver).scroll_to_element(jd_elements[-1]).perform()
        except Exception as e:
            print(f"   - ìŠ¤í¬ë¡¤ ì¤‘ ì‚¬ì†Œí•œ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
        time.sleep(random.uniform(1, 2))
        page_source = driver.page_source
        if "ì±„ìš©ì •ë³´ ê²€ìƒ‰ê²°ê³¼ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤." in page_source:
            print("âœ… ë” ì´ìƒ ì±„ìš© ì •ë³´ê°€ ì—†ì–´ ìˆ˜ì§‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."); break
        page_jds = parse_jd_list_page(page_source)
        if not page_jds:
            print("âœ… í˜„ì¬ í˜ì´ì§€ì—ì„œ ê³µê³ ë¥¼ ì°¾ì§€ ëª»í•´ ìˆ˜ì§‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."); break
        all_jds.extend(page_jds)
        current_page += 1
        driver.get(f"{JOBKOREA_SEARCH_URL}#anchorGICnt_{current_page}")
        time.sleep(random.uniform(2, 4))
    raw_df = pd.DataFrame(all_jds)
    print(f"âœ… ì´ {len(raw_df)}ê°œì˜ JD ì •ë³´ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤. ë°ì´í„° ì •ì œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
    clean_df = raw_df.drop_duplicates(subset='JDë§í¬', keep='first').copy()
    clean_df['ê¸°ì—…ëª…'] = clean_df['ê¸°ì—…ëª…'].str.replace(r'\s?\(?ãˆœ\)?|\s?ì£¼ì‹íšŒì‚¬\s?', '', regex=True)
    clean_df = clean_df[~clean_df['ê¸°ì—…ëª…'].isin(EXCLUSION_df['ê¸°ì—…ëª…'])]
    clean_df = clean_df[~clean_df['JDëª…'].str.contains(EXCLUSION_JD_TITLE_PATTERN, na=False)]
    clean_df = clean_df[~clean_df['JDë§í¬'].isin(JD_LIST_df['JDë§í¬'])]
    clean_df.dropna(subset=['ê¸°ì—…ëª…', 'JDë§í¬'], inplace=True)
    clean_df = clean_df[~clean_df['JDë§í¬'].str.contains('joblist')]
    clean_df = clean_df.sort_values(by=['ê¸°ì—…ëª…', 'ë“±ë¡ì¼'], ascending=[True, False]).reset_index(drop=True)
    print(f"âœ… ë°ì´í„° ì •ì œ ì™„ë£Œ. ìµœì¢…ì ìœ¼ë¡œ {len(clean_df)}ê°œì˜ ìƒˆë¡œìš´ JDë¥¼ êµ¬ê¸€ ì‹œíŠ¸ì— ì¶”ê°€í•©ë‹ˆë‹¤.")
    if not clean_df.empty:
        columns_to_save = ['ê¸°ì—…ëª…', 'ê¸°ì—…ë§í¬', 'JDëª…', 'ë“±ë¡ì¼', 'ë§ˆê°ê¸°í•œ', 'JDë§í¬', 'ì‘ì—…ëŒ€ìƒ', 'ìˆ˜ì§‘ì¼ì‹œ']
        Google.append_dataframe_to_gsheet(JD_LIST_sheet, clean_df[columns_to_save])
        print("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ ì™„ë£Œ!")
    else:
        print("â„¹ï¸ ì¶”ê°€í•  ìƒˆë¡œìš´ JDê°€ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ‰ [Phase 1] ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

def run_phase2(driver):
    # Phase 2 ë¡œì§ ... (ì´ì „ê³¼ ë™ì¼)
    print("\nğŸš€ [Phase 2] JD ìƒì„¸ ì •ë³´ ë° ì—°ë½ì²˜ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    print("â³ 'ì „ì²´JD' ì‹œíŠ¸ì—ì„œ ì‘ì—… ëŒ€ìƒì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤...")
    JD_LIST_sheet, JD_LIST_df = Google.OpenGooglesheets(JD_LIST_SPREADSHEET_URL, JD_LIST_SHEET_NAME)
    target_df = JD_LIST_df[JD_LIST_df['ì‘ì—…ëŒ€ìƒ'] == "Wait"].copy()
    if target_df.empty:
        print("âœ… ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•  ìƒˆë¡œìš´ JDê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤."); return
    print(f"âœ… ì´ {len(target_df)}ê±´ì˜ JDì— ëŒ€í•œ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
    ContactSheet = Google.OpenGooglesheets(CONTACT_SPREADSHEET_URL, CONTACT_SHEET_NAME)[0]
    for company_link, group in target_df.groupby('ê¸°ì—…ë§í¬'):
        company_final_data = []
        company_name = group['ê¸°ì—…ëª…'].iloc[0]
        try:
            print(f"\nğŸ¢ ê¸°ì—… '{company_name}' ì •ë³´ ìˆ˜ì§‘ ì‹œì‘...")
            company_details = scrape_company_details(driver, company_link)
            print(f"   - ê¸°ì—… ê¸°ë³¸ ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ.")
            for index, row in group.iterrows():
                jd_link = row['JDë§í¬']; jd_title = row['JDëª…']
                print(f"   - JD: '{jd_title}' ì—°ë½ì²˜ ìˆ˜ì§‘ ì¤‘...")
                contact_details = get_contact_details(driver, jd_link)
                TARGET_COLUMN_INDEX = 7 # Gì—´
                if contact_details:
                    final_data = {
                        'ìˆ˜ì§‘ì¼ì': datetime.datetime.now().strftime("%Y-%m-%d"), 'ê¸°ì—…ëª…': company_name,
                        'ê¸°ì—…ë§í¬': company_link, 'Title': jd_title, 'JDLink': jd_link,
                        **company_details, **contact_details
                    }
                    company_final_data.append(final_data)
                    JD_LIST_sheet.update_cell(index + 2, TARGET_COLUMN_INDEX, "Done")
                    print("     âœ… ì •ë³´ ìˆ˜ì§‘ ë° ìƒíƒœ ì—…ë°ì´íŠ¸ ì™„ë£Œ (Done)")
                else:
                    JD_LIST_sheet.update_cell(index + 2, TARGET_COLUMN_INDEX, "Error")
                    print("     âŒ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨. ìƒíƒœ ì—…ë°ì´íŠ¸ (Error)")
            if company_final_data:
                final_df = pd.DataFrame(company_final_data)
                final_columns_order = [
                    'ìˆ˜ì§‘ì¼ì', 'ê¸°ì—…ëª…', 'ê¸°ì—…ëª…(ê²€ìƒ‰ê²°ê³¼)', 'ê¸°ì—…ë§í¬', 'ê¸°ì—…êµ¬ë¶„', 'ëŒ€í‘œì', 'í™ˆí˜ì´ì§€', 'ì„¤ë¦½ì¼', 'ì‚°ì—…',
                    'ì£¼ìš”ì‚¬ì—…', 'ì‚¬ì›ìˆ˜', 'ë§¤ì¶œì•¡', 'ìë³¸ê¸ˆ', 'ì£¼ì†Œ', 'Title', 'JDLink', 'ì´ë¦„', 'ì†Œì†', 'íœ´ëŒ€ì „í™”',
                    'ì „í™”ë²ˆí˜¸', 'ì´ë©”ì¼'
                ]
                final_df = final_df.reindex(columns=final_columns_order, fill_value='-')
                print(f"   -> '{company_name}' ê¸°ì—…ì˜ JD {len(final_df)}ê±´ì„ êµ¬ê¸€ ì‹œíŠ¸ì— ì €ì¥í•©ë‹ˆë‹¤...")
                Google.append_dataframe_to_gsheet(ContactSheet, final_df)
                print(f"   -> âœ… ì €ì¥ ì™„ë£Œ.")
        except Exception as e:
            print(f"ğŸš¨ ê¸°ì—… '{company_name}' ì²˜ë¦¬ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
            TARGET_COLUMN_INDEX = 7
            for index, row in group.iterrows():
                if JD_LIST_df.loc[index, 'ì‘ì—…ëŒ€ìƒ'] == 'Wait':
                    JD_LIST_sheet.update_cell(index + 2, TARGET_COLUMN_INDEX, "Error")
            continue
    print("\nğŸ‰ [Phase 2] ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

# ==============================================================================
# 4. [ìˆ˜ì •ëœ] ë©”ì¸ ì‹¤í–‰ ë¸”ë¡
# ==============================================================================
def main_task():
    """í¬ë¡¤ë§ì˜ ëª¨ë“  ê³¼ì •ì„ ìˆ˜í–‰í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜"""
    driver = None
    try:
        driver = initialize_driver()
        login_to_jobkorea(driver, JOBKOREA_ID, JOBKOREA_PW)
        run_phase1(driver)
        run_phase2(driver)
    except Exception as e:
        print(f"ğŸ’¥ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì¹˜ëª…ì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
    finally:
        if driver:
            driver.quit()
        print("ğŸ”š í¬ë¡¤ë§ ì‘ì—… ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    while True:
        now = datetime.datetime.now()
        
        # ë§¤ì¼ ì•„ì¹¨ 7ì‹œ 00ë¶„ì—ë§Œ ì‹¤í–‰ë˜ë„ë¡ ì¡°ê±´ ì„¤ì •
        if now.hour == 7 and now.minute == 0:
            print(f"==== {now.strftime('%Y-%m-%d %H:%M:%S')} ====")
            print("ëª©í‘œ ì‹œê°(07:00)ì´ë¯€ë¡œ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            main_task()
            print("í¬ë¡¤ë§ ì‘ì—…ì„ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì‹¤í–‰ê¹Œì§€ ëŒ€ê¸°í•©ë‹ˆë‹¤.")
        else:
            # í˜„ì¬ ì‹œê°„ì„ 1ë¶„ë§ˆë‹¤ ë³´ì—¬ì£¼ì–´ ì„œë²„ê°€ ì‚´ì•„ìˆëŠ”ì§€ í™•ì¸í•˜ê¸° ìš©ì´í•˜ê²Œ í•¨
            print(f"í˜„ì¬ ì‹œê° {now.strftime('%H:%M:%S')}. 07:00ê¹Œì§€ ëŒ€ê¸° ì¤‘...")
            
        # 60ì´ˆ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹œê°„ ì²´í¬
        time.sleep(60)
